You are tasked with optimizing the following code to improve its performance. This involves reducing latency, reducing CPU cycles, minimizing memory access, and optimizing I/O operations. Please follow these steps and guidelines:

Task Instructions:
- Analyze the code: Examine the provided code in detail.
- Analyze the optimization pattern: Develop an effective strategy for integrating the optimization pattern in the code. DO NOT create your own optimization patterns. Only generate ONE strategy.
- Implement the strategy: Rewrite the code with the chosen optimization strategy, ensuring:
    - The optimized code produces the same output as the original code for all valid inputs.
- Output Requirements:
    - Return the following:
        - Analysis of the code.
        - Proposed optimization strategy in detail.
        - The final code--code with optimization strategy integrated.
        - The optimization pattern name, description, and rank.

Optimization Pattern:
{optimization_pattern}

Here is an example of desirable response:
Example of cpp code to be optimized:
```
#include <iostream>
#include <vector>

using namespace std;

// Inefficient code for finding duplicates in a vector of user IDs
vector<int> findDuplicates(const vector<int>& userIds) {
    vector<int> duplicates;
    for (size_t i = 0; i < userIds.size(); ++i) {
        for (size_t j = i + 1; j < userIds.size(); ++j) {
            if (userIds[i] == userIds[j]) {
                duplicates.push_back(userIds[i]);
            }
        }
    }
    return duplicates;
}

int main() {
    vector<int> userIds = {1, 2, 3, 2, 4, 5, 1, 3, 5};
    vector<int> duplicates = findDuplicates(userIds);

    cout << "Duplicate user IDs: ";
    for (int id : duplicates) {
        cout << id << " ";
    }
    cout << endl;

    return 0;
}
```
Example of Analysis:
Analysis and reasoning example:
    - Reduction of Nested Loops: Uses an O(nÂ²) approach with nested loops.
    - Efficient Data Structure Selection: Using an unordered_set to track seen user IDs reduces complexity to O(n).
    - Dynamic Programming or Memoization: Not required here as each ID is processed once with an efficient data structure.
    - Specialized Algorithms: Using hashing-based data structures effectively reduces redundant checks.
    - I/O Optimization: Minimal I/O operations are used. Keep output operations efficient and straightforward.
                
Here is the actual optimized code: 
```
#include <iostream>
#include <vector>
#include <unordered_set>

using namespace std;

// Optimized code for finding duplicates in a vector of user IDs
vector<int> findDuplicates(const vector<int>& userIds) {
    unordered_set<int> seen;  // Set to track seen user IDs
    unordered_set<int> duplicates;  // Set to store duplicates
    for (int id : userIds) {
        if (seen.find(id) != seen.end()) {
            duplicates.insert(id);  // Add to duplicates if already seen
        } else {
            seen.insert(id);  // Mark as seen
        }
    }
    return vector<int>(duplicates.begin(), duplicates.end());  // Convert set to vector
}

int main() {
    vector<int> userIds = {1, 2, 3, 2, 4, 5, 1, 3, 5};
    vector<int> duplicates = findDuplicates(userIds);

    cout << "Duplicate user IDs: ";
    for (int id : duplicates) {
        cout << id << " ";
    }
    cout << endl;

    return 0;
}
```